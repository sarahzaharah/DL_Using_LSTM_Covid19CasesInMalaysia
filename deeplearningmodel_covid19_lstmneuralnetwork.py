# -*- coding: utf-8 -*-
"""DeepLearningModel_Covid19_LSTMNeuralNetwork.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oCCCs9XbFLxXrSwXYPY4b6X9EDlD7EaR
"""

#library
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras import Sequential, Input
from tensorflow.keras.callbacks import TensorBoard, EarlyStopping
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import os

#Data Loading
PATH_CSV = os.path.join(os.getcwd(), 'dataset', 'cases_malaysia_train.csv')
df = pd.read_csv(PATH_CSV)

#Data Inspsection / Data visualisation
df.head() #see NaN
df.tail()
df.info() #data, cases_new in object format
df.describe().T #


plt.figure()
plt.plot(df['cases_new'].values)
plt.show()

#Data Cleaning 
df['cases_new'] = pd.to_numeric(df['cases_new'], errors = 'coerce') # invalid parsing will be set as NaN

plt.figure()
plt.plot(df['cases_new'].values)
plt.show()

print(df.isna().sum())  #count number of NAN = 12

##Interpolation #dont drop NaN use interpolate instead
df['cases_new'] = df['cases_new'].interpolate(method='polynomial', order=2)

plt.figure()
plt.plot(df['cases_new'].values)
plt.show()

print(df.isna().sum()) #confirm NAN has been removed = 0

#Feature selection
new_cases = df['cases_new'].values

#data preprocessing
#Reshape method
mms = MinMaxScaler()
new_cases = mms.fit_transform(new_cases.reshape(-1,1)) #expand the dimension 

# To split x and y 
X = []
y = []
win_size = 30

for i in range( win_size, len(new_cases)):
  X.append(new_cases[i-win_size : i])
  y.append(new_cases[i])

#convert list to array

X = np.array(X)
y = np.array(y)


X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, shuffle = True, random_state=123)

# Model Development
model = Sequential()

model.add(Input(shape =(X_train.shape[1:]))) #input need match to 60,1 in X_train
model.add(LSTM(8)) #accept only 3D, not 2D below #return_sequences purpose to pass to another layer
model.add(Dense(1, activation ='relu')) #output layer

model.summary() #checking number of neuron = 338

model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mse','mape'] )

# Commented out IPython magic to ensure Python compatibility.
import datetime #code for vs code with tensor board
LOGS_PATH = os.path.join(os.getcwd(),'logs', datetime.datetime.now().strftime('%Y%m%d-%H%M%S')) #write into folder call 'logs'


ts_callback = TensorBoard(log_dir = LOGS_PATH)
es_callback = EarlyStopping(monitor ='val_loss', patience = 5, verbose =0 , restore_best_weights = True)


#TensorBoard callback
# %load_ext tensorboard
# %tensorboard --logdir logs #plot from logs folder

#model.fit(X_train, y_train, validation_data =(X_test, y_test) , epochs =10, batch_size = 64, callbacks = [es_callback, ts_callback])
model.fit(X_train, y_train, epochs =10, batch_size = 64, callbacks = [es_callback, ts_callback])

model.summary()
model.predict(X_train)

#Model Analysis & Evaluation
TEST_PATH_CSV = os.path.join(os.getcwd(), 'dataset', 'cases_malaysia_test.csv')
test_df = pd.read_csv(TEST_PATH_CSV) 

#print(test_df.isna().sum()) #count number of NAN

##Interpolation #dont drop NaN use interpolate instead
test_df['cases_new'] = test_df['cases_new'].interpolate(method='polynomial', order=2)
print(test_df.isna().sum()) # NaN = 0

#concatenate both test & train dataset
concat = pd.concat((df['cases_new'], test_df['cases_new'])) 
concat= concat[len(df['cases_new']) - win_size:]   #slicing 

#minmax transformation
concat = mms.transform(concat[::, None])

X_testtest = []
y_testtest = []

for i in range(win_size, len(concat)):
  X_testtest.append(concat[i-win_size:i])
  y_testtest.append(concat[i])

X_testtest = np.array(X_testtest)
y_testtest = np.array(y_testtest)

predicted_cases = model.predict(X_testtest) #predict unseen dataset

plt.figure()
plt.plot(predicted_cases)
plt.plot(y_testtest)
plt.legend(['Predicted','Actual'])
plt.xlabel('time')
plt.ylabel('Covid19_Trend')
plt.show()




#actual vs predicted
print(mean_absolute_percentage_error(y_testtest, predicted_cases))
print(mean_absolute_error(y_testtest, predicted_cases))
print(mean_squared_error(y_testtest,predicted_cases))